{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guptaml/ai_notebooks/blob/main/pdf_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKSihbUOowsc"
      },
      "source": [
        "# PDF Summarizer (Kaggle/Colab/Local Support)\n",
        "## High-Performance Parallel Processing Edition\n",
        "This notebook supports Google Colab, Kaggle, and Local environments with automatic GPU detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2RLWd4Oowsd",
        "outputId": "724c09a6-e3c1-4d35-ba28-4aeb78761012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import os\n",
        "    if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
        "        print(\"Running on Kaggle.\")\n",
        "        %pip install -q --no-cache-dir --no-input \"gpt4all[cuda]\" pdfplumber pypdf\n",
        "    elif 'google.colab' in str(get_ipython()):\n",
        "        print(\"Running on Google Colab.\")\n",
        "        %pip install -q --no-cache-dir --no-input \"gpt4all[cuda]\" pdfplumber pypdf\n",
        "    else:\n",
        "        print(\"Running Locally.\")\n",
        "        %pip install --no-cache-dir --no-input gpt4all pdfplumber pypdf\n",
        "except Exception:\n",
        "    print(\"Running Locally.\")\n",
        "    %pip install --no-cache-dir --no-input gpt4all pdfplumber pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5apvfOerowse"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import os\n",
        "import sys\n",
        "from gpt4all import GPT4All\n",
        "import pdfplumber\n",
        "from pypdf import PdfReader\n",
        "\n",
        "class Summarizer:\n",
        "    def __init__(self, model_name=\"Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf\", device=\"gpu\"):\n",
        "        print(f\"  -> Loading model: {model_name} on {device}...\")\n",
        "        # n_ctx=8192 for large context support\n",
        "        self.model = GPT4All(model_name, device=device, n_ctx=8192)\n",
        "        self.model_lock = threading.Lock()\n",
        "        print(f\"  -> Model loaded successfully\")\n",
        "\n",
        "    def _summarize_chunk(self, chunk, i, total_chunks):\n",
        "        print(f\"     -> Starting chunk {i}/{total_chunks}...\")\n",
        "        prompt = f\"Briefly summarize this part:\\n\\n{chunk}\"\n",
        "        with self.model_lock:\n",
        "            with self.model.chat_session():\n",
        "                return self.model.generate(prompt, max_tokens=256)\n",
        "\n",
        "    def get_summary_text(self, content, max_words=200):\n",
        "        words = content.split()\n",
        "        total_words = len(words)\n",
        "        chunk_size = 1200\n",
        "\n",
        "        if total_words > 6000:\n",
        "            print(f\"  -> Truncating long content to 6000 words.\")\n",
        "            words = words[:6000]\n",
        "            content = \" \".join(words)\n",
        "            total_words = 6000\n",
        "\n",
        "        if total_words <= chunk_size:\n",
        "            print(f\"  -> Content loaded ({total_words} words)\")\n",
        "            prompt = f\"Summarize the following in {max_words} words:\\n\\n{content}\"\n",
        "            with self.model.chat_session():\n",
        "                return self.model.generate(prompt, max_tokens=512)\n",
        "        else:\n",
        "            chunks = [\" \".join(words[i : i + chunk_size]) for i in range(0, total_words, chunk_size)]\n",
        "            total_chunks = len(chunks)\n",
        "            print(f\"  -> Processing in {total_chunks} chunks (Parallel)... \")\n",
        "\n",
        "            with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "                futures = [executor.submit(self._summarize_chunk, chunk, i, total_chunks)\n",
        "                           for i, chunk in enumerate(chunks, 1)]\n",
        "                chunk_summaries = [f.result() for f in futures]\n",
        "\n",
        "            print(\"  -> Creating final summary from combined chunks...\")\n",
        "            combined_text = \"\\n\\n\".join(chunk_summaries)\n",
        "            final_prompt = f\"Cohesively summarize these parts into a {max_words} word summary:\\n\\n{combined_text}\"\n",
        "            with self.model.chat_session():\n",
        "                return self.model.generate(final_prompt, max_tokens=512)\n",
        "\n",
        "class PDFExtractor:\n",
        "    def __init__(self, pdf_path): self.pdf_path = pdf_path\n",
        "    def get_page_count(self):\n",
        "        with pdfplumber.open(self.pdf_path) as pdf: return len(pdf.pages)\n",
        "    def extract_all_text(self):\n",
        "        with pdfplumber.open(self.pdf_path) as pdf:\n",
        "            return \"\\n\".join([p.extract_text() for p in pdf.pages if p.extract_text()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhueYgCaowse",
        "outputId": "e81237eb-5c2d-4298-a3b8-c1cd7c58154a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting text from ifrs9.pdf...\n",
            "Extracted text written to custom_knowledge.txt\n",
            "Text extracted successfully.\n"
          ]
        }
      ],
      "source": [
        "# 1. CONFIGURATION\n",
        "PDF_FILE = \"ifrs9.pdf\"\n",
        "MODEL_NAME = \"Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf\"\n",
        "\n",
        "IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "DEVICE = \"cuda\" if (IS_KAGGLE or IS_COLAB) else \"gpu\"\n",
        "\n",
        "if not os.path.exists(PDF_FILE):\n",
        "    print(f\"Warning: {PDF_FILE} not found. Please upload it.\")\n",
        "else:\n",
        "    extractor = PDFExtractor(PDF_FILE)\n",
        "    print(f\"Extracting text from {PDF_FILE}...\")\n",
        "    custom_knowledge = extractor.extract_all_text()\n",
        "\n",
        "    output_file = \"custom_knowledge.txt\"\n",
        "\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(custom_knowledge)\n",
        "\n",
        "    print(f\"Extracted text written to {output_file}\")\n",
        "    print(\"Text extracted successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFD3sqYlowse",
        "outputId": "f6d74bb7-c268-4a1e-ff75-22227f36f17b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Loading model: Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf on cuda...\n",
            "  -> Model loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# 2. LOAD MODEL\n",
        "summarizer = Summarizer(model_name=MODEL_NAME, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbJAv6Uqowsf",
        "outputId": "caef9590-828f-45da-cb61-7a26326ed010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating summary...\n",
            "  -> Truncating long content to 6000 words.\n",
            "  -> Processing in 5 chunks (Parallel)... \n",
            "     -> Starting chunk 1/5...\n",
            "     -> Starting chunk 2/5...\n",
            "     -> Starting chunk 3/5...\n",
            "     -> Starting chunk 4/5...\n",
            "     -> Starting chunk 5/5...\n",
            "  -> Creating final summary from combined chunks...\n",
            "\n",
            "RESPONSE:\n",
            " Here is a 200-word summary of the provided texts:\n",
            "\n",
            "IFRS 9 is an international financial reporting standard for accounting for financial instruments. It was developed by the International Accounting Standards Board (IASB) and replaced IAS 39 in July 2014 after several amendments and additions. The key changes include permitting entities to choose between applying hedge accounting requirements from either IFRS 9 or IAS 39, introducing a 'fair value through other comprehensive income' measurement category for simple debt instruments, and adding impairment requirements related to expected credit losses on financial assets.\n",
            "\n",
            "IFRS 9 applies to all entities except specific cases where other standards take precedence. It covers contracts that can be settled in cash or other financial instruments, outlining how these contracts should be recognized and derecognized (i.e., removed from the balance sheet) on a company's statement of financial position. The standard also provides guidance on recognizing financial assets and liabilities, derecognizing financial assets, and applying these rules in consolidated financial statements.\n",
            "\n",
            "The scope of IFRS 9 includes derivatives, finance lease receivables, operating lease receivables recognized by a lessor, loan commitments that meet specific criteria, and embedded derivatives within leases. The standard also applies to contracts for non-financial items that can be settled in cash or other financial instruments.\n"
          ]
        }
      ],
      "source": [
        "# 3. SUMMARIZE\n",
        "if 'custom_knowledge' in locals():\n",
        "    print(\"Generating summary...\")\n",
        "    response = summarizer.get_summary_text(custom_knowledge, max_words=200)\n",
        "    print(\"\\nRESPONSE:\\n\", response)\n",
        "else:\n",
        "    print(\"Error: No knowledge extracted.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Q&A - Ask questions about the document\n",
        "def ask_pdf(question):\n",
        "    # Access variables from the notebook's global scope\n",
        "    kb = globals().get('custom_knowledge')\n",
        "    sm = globals().get('summarizer')\n",
        "\n",
        "    if kb and sm:\n",
        "        # Truncate context for Q&A to fit within model limits\n",
        "        words = kb.split()\n",
        "        context = ' '.join(words[:4000]) if len(words) > 4000 else kb\n",
        "\n",
        "        prompt = f'Answer based ONLY on this content:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:'\n",
        "        print(f'\\nQuestion: {question}')\n",
        "\n",
        "        with sm.model_lock:\n",
        "            with sm.model.chat_session():\n",
        "                response = sm.model.generate(prompt, max_tokens=1024)\n",
        "        print('\\nRESPONSE:\\n', response)\n",
        "    else:\n",
        "        print('Error: Missing custom_knowledge or summarizer. Please run the extraction and model load cells first.')\n",
        "\n",
        "# Example Usage:\n",
        "ask_pdf('What is a virtual network ?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCEnD1MLCyOF",
        "outputId": "5601c43e-ddd3-4e8c-faaf-f8e4cdc41898"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: What is a virtual network ?\n",
            "\n",
            "RESPONSE:\n",
            " There is no information provided about \"a virtual network\" in the given content, which appears to be related to IFRS 9 Financial Instruments. Therefore, I cannot provide an answer based solely on this content. If you have any other questions or need further assistance with a different topic, please let me know!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}